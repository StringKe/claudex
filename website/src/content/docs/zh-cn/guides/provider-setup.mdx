---
title: Provider 配置指南
description: 每个 AI 提供商的详细配置步骤
---

import { Aside, Tabs, TabItem } from '@astrojs/starlight/components';

本指南详细介绍 Claudex 支持的每个提供商的配置方法，包括 API Key 提供商、OAuth 订阅和本地模型。

## API Key 提供商

### Anthropic

1. 在 [console.anthropic.com](https://console.anthropic.com/) 注册
2. 进入 **API Keys** 页面创建密钥（格式：`sk-ant-*`）

```toml
[[profiles]]
name = "anthropic"
provider_type = "DirectAnthropic"
base_url = "https://api.anthropic.com"
api_key = "sk-ant-..."
default_model = "claude-sonnet-4-20250514"
```

```bash
claudex profile test anthropic
```

### MiniMax

1. 在 [platform.minimaxi.com](https://platform.minimaxi.com/) 注册
2. 在控制台中进入 **API Keys** 页面

```toml
[[profiles]]
name = "minimax"
provider_type = "DirectAnthropic"
base_url = "https://api.minimax.io/anthropic"
api_key = "..."
default_model = "claude-sonnet-4-20250514"
```

```bash
claudex profile test minimax
```

### OpenRouter

1. 在 [openrouter.ai](https://openrouter.ai/) 注册
2. 在 [openrouter.ai/keys](https://openrouter.ai/keys) 获取 API 密钥

```toml
[[profiles]]
name = "openrouter"
provider_type = "OpenAICompatible"
base_url = "https://openrouter.ai/api/v1"
api_key = "sk-or-..."
default_model = "anthropic/claude-sonnet-4"
```

```bash
claudex profile test openrouter
```

<Aside type="tip">
  OpenRouter 支持来自不同提供商的数百个模型。Claude 模型使用 `anthropic/` 前缀。
</Aside>

### Grok (xAI)

1. 在 [console.x.ai](https://console.x.ai/) 注册
2. 在控制台中创建 API 密钥

```toml
[[profiles]]
name = "grok"
provider_type = "OpenAICompatible"
base_url = "https://api.x.ai/v1"
api_key = "xai-..."
default_model = "grok-3-beta"
```

```bash
claudex profile test grok
```

### OpenAI

1. 在 [platform.openai.com](https://platform.openai.com/) 注册
2. 在 [platform.openai.com/api-keys](https://platform.openai.com/api-keys) 创建 API 密钥

```toml
[[profiles]]
name = "chatgpt"
provider_type = "OpenAICompatible"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."
default_model = "gpt-4o"
```

```bash
claudex profile test chatgpt
```

### DeepSeek

1. 在 [platform.deepseek.com](https://platform.deepseek.com/) 注册
2. 在控制台中创建 API 密钥

```toml
[[profiles]]
name = "deepseek"
provider_type = "OpenAICompatible"
base_url = "https://api.deepseek.com"
api_key = "sk-..."
default_model = "deepseek-chat"
```

```bash
claudex profile test deepseek
```

### Kimi / Moonshot

1. 在 [platform.moonshot.cn](https://platform.moonshot.cn/) 注册
2. 在控制台中创建 API 密钥

```toml
[[profiles]]
name = "kimi"
provider_type = "OpenAICompatible"
base_url = "https://api.moonshot.cn/v1"
api_key = "sk-..."
default_model = "moonshot-v1-128k"
```

```bash
claudex profile test kimi
```

### GLM / 智谱

1. 在 [open.bigmodel.cn](https://open.bigmodel.cn/) 注册
2. 在控制台中创建 API 密钥

```toml
[[profiles]]
name = "glm"
provider_type = "OpenAICompatible"
base_url = "https://open.bigmodel.cn/api/paas/v4"
api_key = "..."
default_model = "glm-4-plus"
```

```bash
claudex profile test glm
```

## OAuth 订阅认证

OAuth 认证允许你使用现有的提供商订阅（ChatGPT Plus、Claude Max 等），无需单独的 API 密钥。

### Claude Max / Pro

使用你现有的 Claude 订阅，通过 Claude Code 的原生 OAuth 会话。

**前置条件**：已安装 Claude Code 且已登录（`claude` 命令正常工作）

```toml
[[profiles]]
name = "claude-sub"
provider_type = "DirectAnthropic"
base_url = "https://api.anthropic.com"
default_model = "claude-sonnet-4-20250514"
auth_type = "oauth"
oauth_provider = "claude"

[profiles.models]
haiku = "claude-haiku-4-20250514"
sonnet = "claude-sonnet-4-20250514"
opus = "claude-opus-4-20250514"
```

<Aside type="note">
  Claude OAuth profile 使用 Gateway 认证模式。Claudex 设置 `ANTHROPIC_AUTH_TOKEN` 而非 `ANTHROPIC_API_KEY`，以避免与 Claude Code 自身的订阅登录冲突。Claude 订阅 profile 会跳过代理。
</Aside>

无需额外的 `claudex auth login` 步骤。Claudex 直接读取 `~/.claude` 中的现有会话。

### ChatGPT Plus / Codex CLI

通过 Codex CLI token 使用你的 ChatGPT Plus 或 Pro 订阅。

**前置条件**：安装 [Codex CLI](https://github.com/openai/codex) 并完成认证：

```bash
# 安装 Codex CLI
npm install -g @openai/codex

# 认证（会打开浏览器）
codex auth
```

然后配置 Claudex：

```toml
[[profiles]]
name = "codex-sub"
provider_type = "OpenAIResponses"
base_url = "https://chatgpt.com/backend-api/codex"
default_model = "gpt-4o"
auth_type = "oauth"
oauth_provider = "openai"

[profiles.models]
haiku = "gpt-4o-mini"
sonnet = "gpt-4o"
opus = "o1-pro"
```

```bash
# 从 Codex CLI 读取 token
claudex auth login openai --profile codex-sub

# 验证
claudex auth status

# 运行
claudex run codex-sub
```

<Aside type="tip">
  `openai` OAuth 提供商使用 `OpenAIResponses` 作为 provider type。这通过 OpenAI Responses API（`/responses` 端点）通信，区别于 Chat Completions API（`/chat/completions`）。
</Aside>

### Google Gemini

通过 OAuth 设备码流程使用你的 Google 账户。

```toml
[[profiles]]
name = "gemini"
provider_type = "OpenAICompatible"
base_url = "https://generativelanguage.googleapis.com/v1beta/openai"
default_model = "gemini-2.5-pro"
auth_type = "oauth"
oauth_provider = "google"

[profiles.models]
haiku = "gemini-2.0-flash"
sonnet = "gemini-2.5-pro"
opus = "gemini-2.5-pro"
```

```bash
# 启动设备码流程（打开浏览器进行 Google 登录）
claudex auth login google --profile gemini

# 验证
claudex auth status
```

### Qwen / 通义千问

通过 OAuth 设备码流程使用你的 Qwen 账户。

```toml
[[profiles]]
name = "qwen-oauth"
provider_type = "OpenAICompatible"
base_url = "https://chat.qwenlm.ai/api/chat/v1"
default_model = "qwen-max"
auth_type = "oauth"
oauth_provider = "qwen"
```

```bash
# 启动设备码流程
claudex auth login qwen --profile qwen-oauth

# 验证
claudex auth status
```

### Kimi / Moonshot (OAuth)

通过 OAuth 设备码流程使用你的 Kimi 账户。

```toml
[[profiles]]
name = "kimi-oauth"
provider_type = "OpenAICompatible"
base_url = "https://api.moonshot.cn/v1"
default_model = "moonshot-v1-128k"
auth_type = "oauth"
oauth_provider = "kimi"
```

```bash
# 启动设备码流程
claudex auth login kimi --profile kimi-oauth

# 验证
claudex auth status
```

### GitHub Copilot

通过 OAuth 设备码流程使用你的 GitHub Copilot 订阅。

```toml
[[profiles]]
name = "github-copilot"
provider_type = "OpenAICompatible"
base_url = "https://api.githubcopilot.com"
default_model = "gpt-4o"
auth_type = "oauth"
oauth_provider = "github"
```

```bash
# 启动设备码流程（打开浏览器进行 GitHub 登录）
claudex auth login github --profile github-copilot

# 验证
claudex auth status
```

## 本地模型

### Ollama

1. 安装 Ollama：[ollama.com](https://ollama.com/)
2. 拉取模型：

```bash
ollama pull qwen2.5:72b
```

3. 配置 Claudex：

```toml
[[profiles]]
name = "local-qwen"
provider_type = "OpenAICompatible"
base_url = "http://localhost:11434/v1"
api_key = ""
default_model = "qwen2.5:72b"
```

```bash
claudex profile test local-qwen
```

<Aside type="note">
  Ollama 不需要 API 密钥。`api_key` 留空或省略即可。
</Aside>

### vLLM

1. 安装并启动 vLLM：

```bash
pip install vllm
vllm serve meta-llama/Llama-3.3-70B-Instruct --port 8000
```

2. 配置 Claudex：

```toml
[[profiles]]
name = "local-llama"
provider_type = "OpenAICompatible"
base_url = "http://localhost:8000/v1"
api_key = ""
default_model = "meta-llama/Llama-3.3-70B-Instruct"
```

### LM Studio

1. 从 [lmstudio.ai](https://lmstudio.ai/) 下载 LM Studio
2. 加载模型并启动本地服务器（默认端口：1234）

```toml
[[profiles]]
name = "lm-studio"
provider_type = "OpenAICompatible"
base_url = "http://localhost:1234/v1"
api_key = ""
default_model = "loaded-model-name"
```

## 验证配置

配置任何提供商后，验证连通性：

```bash
# 测试指定 profile
claudex profile test <profile-name>

# 测试所有 profile
claudex profile test all

# 列出所有已配置的 profile
claudex profile list
```
