---
title: プロバイダーセットアップガイド
description: Claudex で各 AI プロバイダーを設定するためのステップバイステップ手順
---

import { Aside, Tabs, TabItem } from '@astrojs/starlight/components';

このガイドでは、API キープロバイダー、OAuth サブスクリプション、ローカルモデルを含む Claudex がサポートするすべてのプロバイダーの詳細なセットアップ手順を説明します。

## API キープロバイダー

### Anthropic

1. [console.anthropic.com](https://console.anthropic.com/) でサインアップ
2. **API Keys** に移動して新しいキーを作成 (形式: `sk-ant-*`)

```toml
[[profiles]]
name = "anthropic"
provider_type = "DirectAnthropic"
base_url = "https://api.anthropic.com"
api_key = "sk-ant-..."
default_model = "claude-sonnet-4-20250514"
```

```bash
claudex profile test anthropic
```

### MiniMax

1. [platform.minimaxi.com](https://platform.minimaxi.com/) でサインアップ
2. コンソールの **API Keys** に移動

```toml
[[profiles]]
name = "minimax"
provider_type = "DirectAnthropic"
base_url = "https://api.minimax.io/anthropic"
api_key = "..."
default_model = "claude-sonnet-4-20250514"
```

```bash
claudex profile test minimax
```

### OpenRouter

1. [openrouter.ai](https://openrouter.ai/) でサインアップ
2. [openrouter.ai/keys](https://openrouter.ai/keys) で API キーを取得

```toml
[[profiles]]
name = "openrouter"
provider_type = "OpenAICompatible"
base_url = "https://openrouter.ai/api/v1"
api_key = "sk-or-..."
default_model = "anthropic/claude-sonnet-4"
```

```bash
claudex profile test openrouter
```

<Aside type="tip">
  OpenRouter はさまざまなプロバイダーの数百のモデルをサポートしています。Claude モデルには `anthropic/` プレフィックスを使用してください。
</Aside>

### Grok (xAI)

1. [console.x.ai](https://console.x.ai/) でサインアップ
2. コンソールで API キーを作成

```toml
[[profiles]]
name = "grok"
provider_type = "OpenAICompatible"
base_url = "https://api.x.ai/v1"
api_key = "xai-..."
default_model = "grok-3-beta"
```

```bash
claudex profile test grok
```

### OpenAI

1. [platform.openai.com](https://platform.openai.com/) でサインアップ
2. [platform.openai.com/api-keys](https://platform.openai.com/api-keys) で API キーを作成

```toml
[[profiles]]
name = "chatgpt"
provider_type = "OpenAICompatible"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."
default_model = "gpt-4o"
```

```bash
claudex profile test chatgpt
```

### DeepSeek

1. [platform.deepseek.com](https://platform.deepseek.com/) でサインアップ
2. コンソールで API キーを作成

```toml
[[profiles]]
name = "deepseek"
provider_type = "OpenAICompatible"
base_url = "https://api.deepseek.com"
api_key = "sk-..."
default_model = "deepseek-chat"
```

```bash
claudex profile test deepseek
```

### Kimi / Moonshot

1. [platform.moonshot.cn](https://platform.moonshot.cn/) でサインアップ
2. コンソールで API キーを作成

```toml
[[profiles]]
name = "kimi"
provider_type = "OpenAICompatible"
base_url = "https://api.moonshot.cn/v1"
api_key = "sk-..."
default_model = "moonshot-v1-128k"
```

```bash
claudex profile test kimi
```

### GLM / Zhipu

1. [open.bigmodel.cn](https://open.bigmodel.cn/) でサインアップ
2. コンソールで API キーを作成

```toml
[[profiles]]
name = "glm"
provider_type = "OpenAICompatible"
base_url = "https://open.bigmodel.cn/api/paas/v4"
api_key = "..."
default_model = "glm-4-plus"
```

```bash
claudex profile test glm
```

## OAuth サブスクリプション

OAuth 認証により、別途 API キーを取得せず既存のプロバイダーサブスクリプション (ChatGPT Plus、Claude Max など) を使用できます。

### Claude Max / Pro

Claude Code のネイティブ OAuth セッションを通じて既存の Claude サブスクリプションを使用します。

**前提条件**: Claude Code がインストールされてログイン済み (`claude` コマンドが正常に動作すること)

```toml
[[profiles]]
name = "claude-sub"
provider_type = "DirectAnthropic"
base_url = "https://api.anthropic.com"
default_model = "claude-sonnet-4-20250514"
auth_type = "oauth"
oauth_provider = "claude"

[profiles.models]
haiku = "claude-haiku-4-20250514"
sonnet = "claude-sonnet-4-20250514"
opus = "claude-opus-4-20250514"
```

<Aside type="note">
  Claude OAuth プロファイルは特別なゲートウェイ認証モードを使用します。Claudex は Claude Code 自身のサブスクリプションログインとの競合を避けるため、`ANTHROPIC_API_KEY` ではなく `ANTHROPIC_AUTH_TOKEN` を設定します。Claude サブスクリプションプロファイルではプロキシはスキップされます。
</Aside>

別途 `claudex auth login` の手順は不要です。Claudex は `~/.claude` から既存のセッションを読み取ります。

### ChatGPT Plus / Codex CLI

Codex CLI トークンを通じて ChatGPT Plus または Pro サブスクリプションを使用します。

**前提条件**: [Codex CLI](https://github.com/openai/codex) をインストールして認証します:

```bash
# Codex CLI をインストール
npm install -g @openai/codex

# 認証 (ブラウザが開きます)
codex auth
```

次に Claudex を設定します:

```toml
[[profiles]]
name = "codex-sub"
provider_type = "OpenAIResponses"
base_url = "https://chatgpt.com/backend-api/codex"
default_model = "gpt-4o"
auth_type = "oauth"
oauth_provider = "openai"

[profiles.models]
haiku = "gpt-4o-mini"
sonnet = "gpt-4o"
opus = "o1-pro"
```

```bash
# Codex CLI からトークンを読み取る
claudex auth login openai --profile codex-sub

# 確認
claudex auth status

# 実行
claudex run codex-sub
```

<Aside type="tip">
  `openai` OAuth プロバイダーはプロバイダータイプとして `OpenAIResponses` を使用します。これは Chat Completions API (`/chat/completions`) ではなく OpenAI Responses API (`/responses` エンドポイント) を通じて通信します。
</Aside>

### Google Gemini

OAuth デバイスコードフローを通じて Google アカウントを使用します。

```toml
[[profiles]]
name = "gemini"
provider_type = "OpenAICompatible"
base_url = "https://generativelanguage.googleapis.com/v1beta/openai"
default_model = "gemini-2.5-pro"
auth_type = "oauth"
oauth_provider = "google"

[profiles.models]
haiku = "gemini-2.0-flash"
sonnet = "gemini-2.5-pro"
opus = "gemini-2.5-pro"
```

```bash
# デバイスコードフローを開始 (Google ログイン用のブラウザが開きます)
claudex auth login google --profile gemini

# 確認
claudex auth status
```

### Qwen / 通義千問

OAuth デバイスコードフローを通じて Qwen アカウントを使用します。

```toml
[[profiles]]
name = "qwen-oauth"
provider_type = "OpenAICompatible"
base_url = "https://chat.qwenlm.ai/api/chat/v1"
default_model = "qwen-max"
auth_type = "oauth"
oauth_provider = "qwen"
```

```bash
# デバイスコードフローを開始
claudex auth login qwen --profile qwen-oauth

# 確認
claudex auth status
```

### Kimi / Moonshot (OAuth)

OAuth デバイスコードフローを通じて Kimi アカウントを使用します。

```toml
[[profiles]]
name = "kimi-oauth"
provider_type = "OpenAICompatible"
base_url = "https://api.moonshot.cn/v1"
default_model = "moonshot-v1-128k"
auth_type = "oauth"
oauth_provider = "kimi"
```

```bash
# デバイスコードフローを開始
claudex auth login kimi --profile kimi-oauth

# 確認
claudex auth status
```

### GitHub Copilot

OAuth デバイスコードフローを通じて GitHub Copilot サブスクリプションを使用します。

```toml
[[profiles]]
name = "github-copilot"
provider_type = "OpenAICompatible"
base_url = "https://api.githubcopilot.com"
default_model = "gpt-4o"
auth_type = "oauth"
oauth_provider = "github"
```

```bash
# デバイスコードフローを開始 (GitHub ログイン用のブラウザが開きます)
claudex auth login github --profile github-copilot

# 確認
claudex auth status
```

## ローカルモデル

### Ollama

1. Ollama をインストール: [ollama.com](https://ollama.com/)
2. モデルをダウンロード:

```bash
ollama pull qwen2.5:72b
```

3. Claudex を設定:

```toml
[[profiles]]
name = "local-qwen"
provider_type = "OpenAICompatible"
base_url = "http://localhost:11434/v1"
api_key = ""
default_model = "qwen2.5:72b"
```

```bash
claudex profile test local-qwen
```

<Aside type="note">
  Ollama は API キーを必要としません。`api_key` は空のままにするか省略してください。
</Aside>

### vLLM

1. vLLM をインストールして起動:

```bash
pip install vllm
vllm serve meta-llama/Llama-3.3-70B-Instruct --port 8000
```

2. Claudex を設定:

```toml
[[profiles]]
name = "local-llama"
provider_type = "OpenAICompatible"
base_url = "http://localhost:8000/v1"
api_key = ""
default_model = "meta-llama/Llama-3.3-70B-Instruct"
```

### LM Studio

1. [lmstudio.ai](https://lmstudio.ai/) から LM Studio をダウンロード
2. モデルをロードしてローカルサーバーを起動 (デフォルトポート: 1234)

```toml
[[profiles]]
name = "lm-studio"
provider_type = "OpenAICompatible"
base_url = "http://localhost:1234/v1"
api_key = ""
default_model = "loaded-model-name"
```

## セットアップの確認

任意のプロバイダーを設定したら、接続を確認してください:

```bash
# 特定のプロファイルをテスト
claudex profile test <profile-name>

# すべてのプロファイルをテスト
claudex profile test all

# 設定済みのすべてのプロファイルを一覧表示
claudex profile list
```
