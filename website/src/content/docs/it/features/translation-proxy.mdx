---
title: Proxy di Traduzione
description: Traduzione automatica del protocollo da Anthropic a OpenAI
---

import { Aside } from '@astrojs/starlight/components';

Il proxy di traduzione è il nucleo di Claudex. Si interpone tra Claude Code e i tuoi provider AI, convertendo in modo trasparente tra l'API Anthropic Messages e l'API OpenAI Chat Completions.

## Come Funziona

```
Claude Code → richiesta API Anthropic Messages
    │
    └── Proxy Claudex (127.0.0.1:13456)
        │
        ├── provider DirectAnthropic → inoltro con header
        │
        ├── provider OpenAICompatible
        │   ├── Traduzione richiesta: Anthropic → OpenAI Chat Completions
        │   ├── Inoltro al provider
        │   └── Traduzione risposta: OpenAI → Anthropic
        │
        └── provider OpenAIResponses
            ├── Traduzione richiesta: Anthropic → API OpenAI Responses
            ├── Inoltro al provider
            └── Traduzione risposta: Responses → Anthropic
```

## Cosa Viene Tradotto

### Traduzione delle Richieste (Anthropic → OpenAI)

| Anthropic | OpenAI |
|-----------|--------|
| Campo `system` | Messaggio di sistema nell'array `messages` |
| Blocchi `messages[].content` (text, image, tool_use) | `messages[].content` + `tool_calls` |
| Array `tools` (JSON Schema) | Array `tools` (formato function) |
| `tool_choice` | `tool_choice` |
| `max_tokens` | `max_tokens` |
| `temperature`, `top_p` | Mappatura diretta |

### Traduzione delle Risposte (OpenAI → Anthropic)

| OpenAI | Anthropic |
|--------|-----------|
| `choices[0].message.content` | Blocchi `content` |
| `choices[0].message.tool_calls` | Blocchi di contenuto `tool_use` |
| `finish_reason: stop` | `stop_reason: end_turn` |
| `finish_reason: tool_calls` | `stop_reason: tool_use` |
| `usage.prompt_tokens` / `completion_tokens` | `usage.input_tokens` / `output_tokens` |

## Traduzione in Streaming

Claudex supporta completamente lo streaming SSE (Server-Sent Events), traducendo i chunk dello stream OpenAI in eventi stream Anthropic in tempo reale:

| SSE OpenAI | SSE Anthropic |
|------------|---------------|
| Primo chunk | `message_start` + `content_block_start` |
| `choices[0].delta.content` | `content_block_delta` (text_delta) |
| `choices[0].delta.tool_calls` | `content_block_delta` (input_json_delta) |
| `finish_reason` presente | `content_block_stop` + `message_delta` + `message_stop` |

Il traduttore in streaming mantiene una macchina a stati per gestire correttamente l'accumulo delle tool call e i confini dei blocchi di contenuto.

## Provider Supportati

| Provider | Tipo | URL Base |
|----------|------|----------|
| Anthropic | DirectAnthropic | `https://api.anthropic.com` |
| MiniMax | DirectAnthropic | `https://api.minimax.io/anthropic` |
| OpenRouter | OpenAICompatible | `https://openrouter.ai/api/v1` |
| Grok (xAI) | OpenAICompatible | `https://api.x.ai/v1` |
| OpenAI | OpenAICompatible | `https://api.openai.com/v1` |
| DeepSeek | OpenAICompatible | `https://api.deepseek.com` |
| Kimi/Moonshot | OpenAICompatible | `https://api.moonshot.cn/v1` |
| GLM (Zhipu) | OpenAICompatible | `https://open.bigmodel.cn/api/paas/v4` |
| Ollama | OpenAICompatible | `http://localhost:11434/v1` |
| vLLM | OpenAICompatible | `http://localhost:8000/v1` |
| Abbonamento ChatGPT/Codex | OpenAIResponses | `https://chatgpt.com/backend-api/codex` |

<Aside type="tip">
  I provider DirectAnthropic non richiedono traduzione. I provider OpenAIResponses usano l'API Responses (endpoint `/responses`) invece di Chat Completions (`/chat/completions`).
</Aside>

## Gestione del Proxy

```bash
# Avvia il proxy come daemon
claudex proxy start -d

# Verifica lo stato del proxy
claudex proxy status

# Ferma il daemon del proxy
claudex proxy stop

# Avvia su una porta personalizzata
claudex proxy start -p 8080
```

Quando esegui `claudex run <profile>`, il proxy viene avviato automaticamente in background se non è già in esecuzione.
