---
title: Übersetzungsproxy
description: Automatische Protokollübersetzung von Anthropic nach OpenAI
---

import { Aside } from '@astrojs/starlight/components';

Der Übersetzungsproxy ist das Herzstück von Claudex. Er sitzt zwischen Claude Code und den KI-Anbietern und konvertiert transparent zwischen der Anthropic Messages API und der OpenAI Chat Completions API.

## Funktionsweise

```
Claude Code → Anthropic Messages API-Anfrage
    │
    └── Claudex Proxy (127.0.0.1:13456)
        │
        ├── DirectAnthropic-Anbieter → weiterleiten mit Headern
        │
        ├── OpenAICompatible-Anbieter
        │   ├── Anfrage übersetzen: Anthropic → OpenAI Chat Completions
        │   ├── An Anbieter weiterleiten
        │   └── Antwort übersetzen: OpenAI → Anthropic
        │
        └── OpenAIResponses-Anbieter
            ├── Anfrage übersetzen: Anthropic → OpenAI Responses API
            ├── An Anbieter weiterleiten
            └── Antwort übersetzen: Responses → Anthropic
```

## Was übersetzt wird

### Anfragenübersetzung (Anthropic → OpenAI)

| Anthropic | OpenAI |
|-----------|--------|
| `system`-Feld | System-Nachricht im `messages`-Array |
| `messages[].content`-Blöcke (text, image, tool_use) | `messages[].content` + `tool_calls` |
| `tools`-Array (JSON Schema) | `tools`-Array (Funktionsformat) |
| `tool_choice` | `tool_choice` |
| `max_tokens` | `max_tokens` |
| `temperature`, `top_p` | Direkte Zuordnung |

### Antwortübersetzung (OpenAI → Anthropic)

| OpenAI | Anthropic |
|--------|-----------|
| `choices[0].message.content` | `content`-Blöcke |
| `choices[0].message.tool_calls` | `tool_use`-Inhaltsblöcke |
| `finish_reason: stop` | `stop_reason: end_turn` |
| `finish_reason: tool_calls` | `stop_reason: tool_use` |
| `usage.prompt_tokens` / `completion_tokens` | `usage.input_tokens` / `output_tokens` |

## Streaming-Übersetzung

Claudex unterstützt vollständig SSE (Server-Sent Events) Streaming und übersetzt OpenAI-Stream-Chunks in Echtzeit in Anthropic-Stream-Events:

| OpenAI SSE | Anthropic SSE |
|------------|---------------|
| Erster Chunk | `message_start` + `content_block_start` |
| `choices[0].delta.content` | `content_block_delta` (text_delta) |
| `choices[0].delta.tool_calls` | `content_block_delta` (input_json_delta) |
| `finish_reason` vorhanden | `content_block_stop` + `message_delta` + `message_stop` |

Der Streaming-Übersetzer pflegt eine Zustandsmaschine zur korrekten Behandlung der Tool-Call-Akkumulation und der Inhaltsblock-Grenzen.

## Unterstützte Anbieter

| Anbieter | Typ | Basis-URL |
|----------|------|----------|
| Anthropic | DirectAnthropic | `https://api.anthropic.com` |
| MiniMax | DirectAnthropic | `https://api.minimax.io/anthropic` |
| OpenRouter | OpenAICompatible | `https://openrouter.ai/api/v1` |
| Grok (xAI) | OpenAICompatible | `https://api.x.ai/v1` |
| OpenAI | OpenAICompatible | `https://api.openai.com/v1` |
| DeepSeek | OpenAICompatible | `https://api.deepseek.com` |
| Kimi/Moonshot | OpenAICompatible | `https://api.moonshot.cn/v1` |
| GLM (Zhipu) | OpenAICompatible | `https://open.bigmodel.cn/api/paas/v4` |
| Ollama | OpenAICompatible | `http://localhost:11434/v1` |
| vLLM | OpenAICompatible | `http://localhost:8000/v1` |
| ChatGPT/Codex-Abonnement | OpenAIResponses | `https://chatgpt.com/backend-api/codex` |

<Aside type="tip">
  DirectAnthropic-Anbieter benötigen keine Übersetzung. OpenAIResponses-Anbieter verwenden die Responses API (`/responses`-Endpunkt) statt Chat Completions (`/chat/completions`).
</Aside>

## Proxy-Verwaltung

```bash
# Proxy als Daemon starten
claudex proxy start -d

# Proxy-Status prüfen
claudex proxy status

# Proxy-Daemon stoppen
claudex proxy stop

# Auf einem benutzerdefinierten Port starten
claudex proxy start -p 8080
```

Beim Ausführen von `claudex run <profile>` wird der Proxy automatisch im Hintergrund gestartet, falls noch nicht aktiv.
