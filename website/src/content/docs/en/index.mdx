---
title: Multi-instance Claude Code Manager
description: Multi-instance Claude Code manager with intelligent translation proxy
template: splash
hero:
  title: Claudex
  tagline: Use Claude Code with any AI provider — Grok, ChatGPT, DeepSeek, Gemini, Kimi, GLM, Ollama, Azure, Groq, Mistral, and 20+ more.
  actions:
    - text: Get Started
      link: /en/installation/
      icon: right-arrow
      variant: primary
    - text: View on GitHub
      link: https://github.com/StringKe/claudex
      icon: external
      variant: minimal
---

import { Card, CardGrid } from '@astrojs/starlight/components';

## Features

<CardGrid stagger>
  <Card title="Translation Proxy" icon="translate">
    Automatic Anthropic-to-OpenAI protocol translation. Use Claude Code with 20+ providers including Grok, ChatGPT, DeepSeek, Gemini, Kimi, GLM, Azure OpenAI, Groq, Mistral, Together AI, Perplexity, Cerebras, and any OpenAI-compatible endpoint.
  </Card>
  <Card title="Circuit Breaker" icon="warning">
    Per-profile circuit breaker with automatic failover to backup providers. Configurable failure thresholds, recovery timeouts, and OAuth 401 retry with token refresh.
  </Card>
  <Card title="Smart Routing" icon="random">
    Intent-based auto-routing via local classifier. Automatically maps code, analysis, creative, search, and math tasks to the optimal provider profile.
  </Card>
  <Card title="Context Engine" icon="document">
    Conversation compression, cross-profile context sharing, and local RAG with embeddings. Enhance your AI interactions with richer context.
  </Card>
  <Card title="TUI Dashboard" icon="laptop">
    Real-time terminal dashboard showing profile health, request metrics, logs, and quick-launch capabilities. Full keyboard navigation.
  </Card>
  <Card title="Self-Update" icon="up-caret">
    One command to check and install the latest version directly from GitHub Releases. Stay up to date effortlessly.
  </Card>
  <Card title="OAuth Subscriptions" icon="approve-check">
    Use existing Claude, ChatGPT, Google, Qwen, Kimi, GitHub Copilot, or GitLab Duo subscriptions. Supports browser PKCE, device code flow, and credential chain from native CLIs.
  </Card>
  <Card title="Configuration Sets" icon="setting">
    Install and manage reusable bundles of CLAUDE.md rules, skills, and MCP servers via `claudex sets add`. Versioned manifests with conflict detection.
  </Card>
  <Card title="Terminal Hyperlinks" icon="external">
    OSC 8 clickable hyperlinks in terminal output. Auto-detects terminal support (iTerm, WezTerm, Kitty, Ghostty, VS Code, Windows Terminal) with PTY proxy mode.
  </Card>
  <Card title="Model Slot Mapping" icon="puzzle">
    Map Claude Code's `/model` switcher (haiku, sonnet, opus) to any provider model via `[profiles.models]`. Per-profile model configuration with environment variable overrides.
  </Card>
  <Card title="Non-Interactive Mode" icon="rocket">
    One-shot execution with `claudex run <profile> "prompt" --print`. Ideal for CI/CD pipelines and scripted automation.
  </Card>
  <Card title="Tool Name Compatibility" icon="list-format">
    Auto-truncates tool names longer than 64 characters for OpenAI compatibility, with transparent roundtrip restoration on responses.
  </Card>
</CardGrid>

## Supported Providers

| Category | Providers |
|----------|-----------|
| **Direct Anthropic** | Anthropic, MiniMax |
| **OpenAI Compatible** | Grok (xAI), OpenAI, DeepSeek, Kimi/Moonshot, GLM (Zhipu), OpenRouter, Groq, Mistral, Together AI, Perplexity, Cerebras |
| **Cloud Platforms** | Azure OpenAI, Google Vertex AI |
| **OAuth Subscriptions** | Claude Max/Pro, ChatGPT Plus/Pro (Codex), Google Gemini, GitHub Copilot, GitLab Duo, Qwen, Kimi |
| **Local Models** | Ollama, vLLM, LM Studio, llama.cpp |
| **Via LiteLLM** | AWS Bedrock, and any LiteLLM-supported provider |

## Quick Install

```bash
curl -fsSL https://raw.githubusercontent.com/StringKe/claudex/main/install.sh | bash
```

## How It Works

```
claudex run grok
    │
    ├── Start proxy → 127.0.0.1:13456
    │
    └── exec claude with:
        ANTHROPIC_BASE_URL=http://127.0.0.1:13456/proxy/grok
        ANTHROPIC_AUTH_TOKEN=<session-token>
        ANTHROPIC_MODEL=grok-3-beta
```

The proxy transparently translates between Anthropic and OpenAI protocols, so Claude Code works seamlessly with any supported provider. When using OAuth profiles, `ANTHROPIC_AUTH_TOKEN` (not `ANTHROPIC_API_KEY`) is set to avoid conflicts with Claude's own subscription login.
