---
title: Proxy tłumaczące
description: Automatyczne tłumaczenie protokołu Anthropic na OpenAI
---

import { Aside } from '@astrojs/starlight/components';

Proxy tłumaczące jest rdzeniem Claudex. Działa między Claude Code a dostawcami AI, transparentnie konwertując między Anthropic Messages API a OpenAI Chat Completions API.

## Jak to działa

```
Claude Code → żądanie Anthropic Messages API
    │
    └── Proxy Claudex (127.0.0.1:13456)
        │
        ├── Dostawca DirectAnthropic → przekazuje z nagłówkami
        │
        ├── Dostawca OpenAICompatible
        │   ├── Tłumaczenie żądania: Anthropic → OpenAI Chat Completions
        │   ├── Przekazanie do dostawcy
        │   └── Tłumaczenie odpowiedzi: OpenAI → Anthropic
        │
        └── Dostawca OpenAIResponses
            ├── Tłumaczenie żądania: Anthropic → OpenAI Responses API
            ├── Przekazanie do dostawcy
            └── Tłumaczenie odpowiedzi: Responses → Anthropic
```

## Co jest tłumaczone

### Tłumaczenie żądań (Anthropic → OpenAI)

| Anthropic | OpenAI |
|-----------|--------|
| Pole `system` | Wiadomość systemowa w tablicy `messages` |
| Bloki `messages[].content` (text, image, tool_use) | `messages[].content` + `tool_calls` |
| Tablica `tools` (JSON Schema) | Tablica `tools` (format funkcji) |
| `tool_choice` | `tool_choice` |
| `max_tokens` | `max_tokens` |
| `temperature`, `top_p` | Bezpośrednie mapowanie |

### Tłumaczenie odpowiedzi (OpenAI → Anthropic)

| OpenAI | Anthropic |
|--------|-----------|
| `choices[0].message.content` | Bloki `content` |
| `choices[0].message.tool_calls` | Bloki zawartości `tool_use` |
| `finish_reason: stop` | `stop_reason: end_turn` |
| `finish_reason: tool_calls` | `stop_reason: tool_use` |
| `usage.prompt_tokens` / `completion_tokens` | `usage.input_tokens` / `output_tokens` |

## Tłumaczenie strumieniowe

Claudex w pełni obsługuje strumieniowanie SSE (Server-Sent Events), tłumacząc fragmenty strumienia OpenAI na zdarzenia strumienia Anthropic w czasie rzeczywistym:

| OpenAI SSE | Anthropic SSE |
|------------|---------------|
| Pierwszy fragment | `message_start` + `content_block_start` |
| `choices[0].delta.content` | `content_block_delta` (text_delta) |
| `choices[0].delta.tool_calls` | `content_block_delta` (input_json_delta) |
| Obecny `finish_reason` | `content_block_stop` + `message_delta` + `message_stop` |

Translator strumieniowy utrzymuje maszynę stanów do prawidłowej obsługi akumulacji wywołań narzędzi i granic bloków zawartości.

## Obsługiwani dostawcy

| Dostawca | Typ | Base URL |
|----------|-----|----------|
| Anthropic | DirectAnthropic | `https://api.anthropic.com` |
| MiniMax | DirectAnthropic | `https://api.minimax.io/anthropic` |
| OpenRouter | OpenAICompatible | `https://openrouter.ai/api/v1` |
| Grok (xAI) | OpenAICompatible | `https://api.x.ai/v1` |
| OpenAI | OpenAICompatible | `https://api.openai.com/v1` |
| DeepSeek | OpenAICompatible | `https://api.deepseek.com` |
| Kimi/Moonshot | OpenAICompatible | `https://api.moonshot.cn/v1` |
| GLM (Zhipu) | OpenAICompatible | `https://open.bigmodel.cn/api/paas/v4` |
| Ollama | OpenAICompatible | `http://localhost:11434/v1` |
| vLLM | OpenAICompatible | `http://localhost:8000/v1` |
| ChatGPT/Codex sub | OpenAIResponses | `https://chatgpt.com/backend-api/codex` |

<Aside type="tip">
  Dostawcy DirectAnthropic nie wymagają tłumaczenia. Dostawcy OpenAIResponses używają Responses API (endpoint `/responses`) zamiast Chat Completions (`/chat/completions`).
</Aside>

## Zarządzanie proxy

```bash
# Uruchom proxy jako demon
claudex proxy start -d

# Sprawdź status proxy
claudex proxy status

# Zatrzymaj demona proxy
claudex proxy stop

# Uruchom na niestandardowym porcie
claudex proxy start -p 8080
```

Po uruchomieniu `claudex run <profile>` proxy jest automatycznie uruchamiane w tle, jeśli jeszcze nie działa.
