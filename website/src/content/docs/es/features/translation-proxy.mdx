---
title: Proxy de Traduccion
description: Traduccion automatica del protocolo Anthropic a OpenAI
---

import { Aside } from '@astrojs/starlight/components';

El proxy de traduccion es el nucleo de Claudex. Se situa entre Claude Code y tus proveedores de IA, convirtiendo de forma transparente entre la API Anthropic Messages y la API OpenAI Chat Completions.

## Como Funciona

```
Claude Code → Anthropic Messages API request
    │
    └── Claudex Proxy (127.0.0.1:13456)
        │
        ├── DirectAnthropic provider → forward with headers
        │
        ├── OpenAICompatible provider
        │   ├── Translate request: Anthropic → OpenAI Chat Completions
        │   ├── Forward to provider
        │   └── Translate response: OpenAI → Anthropic
        │
        └── OpenAIResponses provider
            ├── Translate request: Anthropic → OpenAI Responses API
            ├── Forward to provider
            └── Translate response: Responses → Anthropic
```

## Que se Traduce

### Traduccion de Solicitudes (Anthropic a OpenAI)

| Anthropic | OpenAI |
|-----------|--------|
| Campo `system` | Mensaje de sistema en el array `messages` |
| Bloques `messages[].content` (text, image, tool_use) | `messages[].content` + `tool_calls` |
| Array `tools` (JSON Schema) | Array `tools` (formato de funcion) |
| `tool_choice` | `tool_choice` |
| `max_tokens` | `max_tokens` |
| `temperature`, `top_p` | Asignacion directa |

### Traduccion de Respuestas (OpenAI a Anthropic)

| OpenAI | Anthropic |
|--------|-----------|
| `choices[0].message.content` | Bloques `content` |
| `choices[0].message.tool_calls` | Bloques de contenido `tool_use` |
| `finish_reason: stop` | `stop_reason: end_turn` |
| `finish_reason: tool_calls` | `stop_reason: tool_use` |
| `usage.prompt_tokens` / `completion_tokens` | `usage.input_tokens` / `output_tokens` |

## Traduccion en Streaming

Claudex soporta completamente el streaming SSE (Server-Sent Events), traduciendo fragmentos del stream de OpenAI a eventos del stream de Anthropic en tiempo real:

| OpenAI SSE | Anthropic SSE |
|------------|---------------|
| Primer fragmento | `message_start` + `content_block_start` |
| `choices[0].delta.content` | `content_block_delta` (text_delta) |
| `choices[0].delta.tool_calls` | `content_block_delta` (input_json_delta) |
| `finish_reason` presente | `content_block_stop` + `message_delta` + `message_stop` |

El traductor de streaming mantiene una maquina de estados para gestionar correctamente la acumulacion de llamadas a herramientas y los limites de bloques de contenido.

## Proveedores Compatibles

| Proveedor | Tipo | URL Base |
|-----------|------|----------|
| Anthropic | DirectAnthropic | `https://api.anthropic.com` |
| MiniMax | DirectAnthropic | `https://api.minimax.io/anthropic` |
| OpenRouter | OpenAICompatible | `https://openrouter.ai/api/v1` |
| Grok (xAI) | OpenAICompatible | `https://api.x.ai/v1` |
| OpenAI | OpenAICompatible | `https://api.openai.com/v1` |
| DeepSeek | OpenAICompatible | `https://api.deepseek.com` |
| Kimi/Moonshot | OpenAICompatible | `https://api.moonshot.cn/v1` |
| GLM (Zhipu) | OpenAICompatible | `https://open.bigmodel.cn/api/paas/v4` |
| Ollama | OpenAICompatible | `http://localhost:11434/v1` |
| vLLM | OpenAICompatible | `http://localhost:8000/v1` |
| ChatGPT/Codex sub | OpenAIResponses | `https://chatgpt.com/backend-api/codex` |

<Aside type="tip">
  Los proveedores DirectAnthropic no requieren traduccion. Los proveedores OpenAIResponses usan la API Responses (endpoint `/responses`) en lugar de Chat Completions (`/chat/completions`).
</Aside>

## Gestion del Proxy

```bash
# Iniciar el proxy como daemon
claudex proxy start -d

# Comprobar el estado del proxy
claudex proxy status

# Detener el daemon del proxy
claudex proxy stop

# Iniciar en un puerto personalizado
claudex proxy start -p 8080
```

Cuando ejecutas `claudex run <profile>`, el proxy se inicia automaticamente en segundo plano si no esta ya en ejecucion.
