---
title: Proxy de Traducao
description: Traducao automatica de protocolo Anthropic para OpenAI
---

import { Aside } from '@astrojs/starlight/components';

O proxy de traducao e o nucleo do Claudex. Ele se posiciona entre o Claude Code e seus provedores de IA, convertendo de forma transparente entre a API Anthropic Messages e a API OpenAI Chat Completions.

## Como Funciona

```
Claude Code → requisicao da API Anthropic Messages
    │
    └── Proxy Claudex (127.0.0.1:13456)
        │
        ├── Provedor DirectAnthropic → encaminhar com cabecalhos
        │
        ├── Provedor OpenAICompatible
        │   ├── Traduzir requisicao: Anthropic → OpenAI Chat Completions
        │   ├── Encaminhar para o provedor
        │   └── Traduzir resposta: OpenAI → Anthropic
        │
        └── Provedor OpenAIResponses
            ├── Traduzir requisicao: Anthropic → API OpenAI Responses
            ├── Encaminhar para o provedor
            └── Traduzir resposta: Responses → Anthropic
```

## O que e Traduzido

### Traducao de Requisicao (Anthropic → OpenAI)

| Anthropic | OpenAI |
|-----------|--------|
| Campo `system` | Mensagem de sistema no array `messages` |
| Blocos `messages[].content` (text, image, tool_use) | `messages[].content` + `tool_calls` |
| Array `tools` (JSON Schema) | Array `tools` (formato function) |
| `tool_choice` | `tool_choice` |
| `max_tokens` | `max_tokens` |
| `temperature`, `top_p` | Mapeamento direto |

### Traducao de Resposta (OpenAI → Anthropic)

| OpenAI | Anthropic |
|--------|-----------|
| `choices[0].message.content` | Blocos `content` |
| `choices[0].message.tool_calls` | Blocos de conteudo `tool_use` |
| `finish_reason: stop` | `stop_reason: end_turn` |
| `finish_reason: tool_calls` | `stop_reason: tool_use` |
| `usage.prompt_tokens` / `completion_tokens` | `usage.input_tokens` / `output_tokens` |

## Traducao em Streaming

O Claudex suporta completamente SSE (Server-Sent Events) em streaming, traduzindo chunks de stream do OpenAI em eventos de stream do Anthropic em tempo real:

| OpenAI SSE | Anthropic SSE |
|------------|---------------|
| Primeiro chunk | `message_start` + `content_block_start` |
| `choices[0].delta.content` | `content_block_delta` (text_delta) |
| `choices[0].delta.tool_calls` | `content_block_delta` (input_json_delta) |
| `finish_reason` presente | `content_block_stop` + `message_delta` + `message_stop` |

O tradutor de streaming mantem uma maquina de estados para tratar corretamente o acumulo de chamadas de ferramentas e os limites de blocos de conteudo.

## Provedores Suportados

| Provedor | Tipo | URL Base |
|----------|------|----------|
| Anthropic | DirectAnthropic | `https://api.anthropic.com` |
| MiniMax | DirectAnthropic | `https://api.minimax.io/anthropic` |
| OpenRouter | OpenAICompatible | `https://openrouter.ai/api/v1` |
| Grok (xAI) | OpenAICompatible | `https://api.x.ai/v1` |
| OpenAI | OpenAICompatible | `https://api.openai.com/v1` |
| DeepSeek | OpenAICompatible | `https://api.deepseek.com` |
| Kimi/Moonshot | OpenAICompatible | `https://api.moonshot.cn/v1` |
| GLM (Zhipu) | OpenAICompatible | `https://open.bigmodel.cn/api/paas/v4` |
| Ollama | OpenAICompatible | `http://localhost:11434/v1` |
| vLLM | OpenAICompatible | `http://localhost:8000/v1` |
| Assinatura ChatGPT/Codex | OpenAIResponses | `https://chatgpt.com/backend-api/codex` |

<Aside type="tip">
  Provedores DirectAnthropic nao requerem traducao. Provedores OpenAIResponses usam a API Responses (endpoint `/responses`) em vez de Chat Completions (`/chat/completions`).
</Aside>

## Gerenciamento do Proxy

```bash
# Iniciar proxy como daemon
claudex proxy start -d

# Verificar status do proxy
claudex proxy status

# Parar daemon do proxy
claudex proxy stop

# Iniciar em uma porta personalizada
claudex proxy start -p 8080
```

Quando voce executa `claudex run <profile>`, o proxy e iniciado automaticamente em segundo plano se ainda nao estiver em execucao.
