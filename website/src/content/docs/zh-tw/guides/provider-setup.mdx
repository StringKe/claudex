---
title: 提供商設定指南
description: 為 Claudex 設定各 AI 提供商的逐步說明
---

import { Aside, Tabs, TabItem } from '@astrojs/starlight/components';

本指南涵蓋 Claudex 支援的每個提供商的詳細設定說明，包括 API 金鑰提供商、OAuth 訂閱、雲端平台和本地模型。

## API 金鑰提供商

### Anthropic

1. 在 [console.anthropic.com](https://console.anthropic.com/) 註冊
2. 前往 **API Keys** 並建立新金鑰（格式：`sk-ant-*`）

```toml
[[profiles]]
name = "anthropic"
provider_type = "DirectAnthropic"
base_url = "https://api.anthropic.com"
api_key = "sk-ant-..."
default_model = "claude-sonnet-4-20250514"
```

```bash
claudex profile test anthropic
```

### MiniMax

1. 在 [platform.minimaxi.com](https://platform.minimaxi.com/) 註冊
2. 前往主控台中的 **API Keys**

```toml
[[profiles]]
name = "minimax"
provider_type = "DirectAnthropic"
base_url = "https://api.minimax.io/anthropic"
api_key = "..."
default_model = "claude-sonnet-4-20250514"
```

```bash
claudex profile test minimax
```

### OpenRouter

1. 在 [openrouter.ai](https://openrouter.ai/) 註冊
2. 在 [openrouter.ai/keys](https://openrouter.ai/keys) 取得你的 API 金鑰

```toml
[[profiles]]
name = "openrouter"
provider_type = "OpenAICompatible"
base_url = "https://openrouter.ai/api/v1"
api_key = "sk-or-..."
default_model = "anthropic/claude-sonnet-4"
```

```bash
claudex profile test openrouter
```

<Aside type="tip">
  OpenRouter 支援來自不同提供商的數百種模型。Claude 模型請使用 `anthropic/` 前綴。
</Aside>

### Grok (xAI)

1. 在 [console.x.ai](https://console.x.ai/) 註冊
2. 在主控台中建立 API 金鑰

```toml
[[profiles]]
name = "grok"
provider_type = "OpenAICompatible"
base_url = "https://api.x.ai/v1"
api_key = "xai-..."
default_model = "grok-3-beta"
```

```bash
claudex profile test grok
```

### OpenAI

1. 在 [platform.openai.com](https://platform.openai.com/) 註冊
2. 在 [platform.openai.com/api-keys](https://platform.openai.com/api-keys) 建立 API 金鑰

```toml
[[profiles]]
name = "chatgpt"
provider_type = "OpenAICompatible"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."
default_model = "gpt-4o"
```

```bash
claudex profile test chatgpt
```

### DeepSeek

1. 在 [platform.deepseek.com](https://platform.deepseek.com/) 註冊
2. 在主控台中建立 API 金鑰

```toml
[[profiles]]
name = "deepseek"
provider_type = "OpenAICompatible"
base_url = "https://api.deepseek.com"
api_key = "sk-..."
default_model = "deepseek-chat"
```

```bash
claudex profile test deepseek
```

### Kimi / Moonshot

1. 在 [platform.moonshot.cn](https://platform.moonshot.cn/) 註冊
2. 在主控台中建立 API 金鑰

```toml
[[profiles]]
name = "kimi"
provider_type = "OpenAICompatible"
base_url = "https://api.moonshot.ai/v1"
api_key = "sk-..."
default_model = "kimi-k2-0905-preview"
```

```bash
claudex profile test kimi
```

### GLM / Zhipu

1. 在 [open.bigmodel.cn](https://open.bigmodel.cn/) 註冊
2. 在主控台中建立 API 金鑰

```toml
[[profiles]]
name = "glm"
provider_type = "OpenAICompatible"
base_url = "https://api.z.ai/api/paas/v4"
api_key = "..."
default_model = "glm-4.6"
```

```bash
claudex profile test glm
```

### Groq

1. 在 [console.groq.com](https://console.groq.com/) 註冊
2. 在 **Settings > API Keys** 建立 API 金鑰

```toml
[[profiles]]
name = "groq"
provider_type = "OpenAICompatible"
base_url = "https://api.groq.com/openai/v1"
api_key = "gsk_..."
default_model = "llama-3.3-70b-versatile"
```

```bash
claudex profile test groq
```

<Aside type="tip">
  Groq 提供極快速的開源模型推論。熱門模型包括 `llama-3.3-70b-versatile`、`mixtral-8x7b-32768` 和 `gemma2-9b-it`。
</Aside>

### Mistral AI

1. 在 [console.mistral.ai](https://console.mistral.ai/) 註冊
2. 在主控台中建立 API 金鑰

```toml
[[profiles]]
name = "mistral"
provider_type = "OpenAICompatible"
base_url = "https://api.mistral.ai/v1"
api_key = "..."
default_model = "mistral-large-latest"
```

```bash
claudex profile test mistral
```

### Together AI

1. 在 [api.together.ai](https://api.together.ai/) 註冊
2. 在儀表板中建立 API 金鑰

```toml
[[profiles]]
name = "together"
provider_type = "OpenAICompatible"
base_url = "https://api.together.xyz/v1"
api_key = "..."
default_model = "meta-llama/Llama-3.3-70B-Instruct-Turbo"
```

```bash
claudex profile test together
```

### Perplexity

1. 在 [perplexity.ai](https://www.perplexity.ai/) 註冊
2. 在 [perplexity.ai/settings/api](https://www.perplexity.ai/settings/api) 建立 API 金鑰

```toml
[[profiles]]
name = "perplexity"
provider_type = "OpenAICompatible"
base_url = "https://api.perplexity.ai"
api_key = "pplx-..."
default_model = "sonar-pro"
```

```bash
claudex profile test perplexity
```

<Aside type="note">
  Perplexity 模型具有內建的網路搜尋功能，適合研究導向的任務。
</Aside>

### Cerebras

1. 在 [cloud.cerebras.ai](https://cloud.cerebras.ai/) 註冊
2. 在儀表板中建立 API 金鑰

```toml
[[profiles]]
name = "cerebras"
provider_type = "OpenAICompatible"
base_url = "https://api.cerebras.ai/v1"
api_key = "..."
default_model = "llama-3.3-70b"
```

```bash
claudex profile test cerebras
```

## 雲端平台

### Azure OpenAI

1. 在 [Azure Portal](https://portal.azure.com/) 建立 Azure OpenAI 資源
2. 部署模型並記下資源名稱和部署名稱
3. 從 **Keys and Endpoint** 取得 API 金鑰

```toml
[[profiles]]
name = "azure-openai"
provider_type = "OpenAICompatible"
base_url = "https://YOUR_RESOURCE.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT"
api_key = "YOUR_AZURE_KEY"
default_model = "gpt-4o"

[profiles.query_params]
api-version = "2024-12-01-preview"
```

```bash
claudex profile test azure-openai
```

<Aside type="note">
  Azure OpenAI 透過 `base_url` 包含 `openai.azure.com` 自動偵測。認證使用 `api-key` 標頭取代 `Authorization: Bearer`。`api-version` 查詢參數為必填。
</Aside>

### Google Vertex AI

1. 在 GCP 專案中啟用 Vertex AI API
2. 使用 `gcloud auth print-access-token` 產生存取權杖

```toml
[[profiles]]
name = "vertex-ai"
provider_type = "DirectAnthropic"
base_url = "https://us-east5-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT/locations/us-east5/publishers/anthropic/models"
api_key = "YOUR_GCLOUD_TOKEN"
default_model = "claude-sonnet-4@20250514"
```

```bash
claudex profile test vertex-ai
```

<Aside type="caution">
  `gcloud auth print-access-token` 的輸出約 1 小時後過期。生產環境建議使用服務帳戶搭配 token 自動刷新。
</Aside>

### AWS Bedrock（透過 LiteLLM）

AWS Bedrock 透過 LiteLLM 代理支援：

1. 安裝 LiteLLM：`pip install litellm`
2. 啟動代理：

```bash
litellm --model bedrock/anthropic.claude-sonnet-4-20250514-v2:0
```

3. 設定 Claudex：

```toml
[[profiles]]
name = "bedrock"
provider_type = "OpenAICompatible"
base_url = "http://localhost:4000/v1"
api_key = "sk-litellm"
default_model = "bedrock/anthropic.claude-sonnet-4-20250514-v2:0"
```

## OAuth 訂閱

OAuth 認證讓你可以使用現有的提供商訂閱（ChatGPT Plus、Claude Max 等），無需單獨的 API 金鑰。

### Claude Max / Pro

透過 Claude Code 的原生 OAuth 工作階段使用你現有的 Claude 訂閱。

**先決條件**：已安裝並登入 Claude Code（`claude` 指令正常運作）

```toml
[[profiles]]
name = "claude-max"
provider_type = "DirectAnthropic"
base_url = "https://api.claude.ai"
default_model = "claude-sonnet-4-20250514"
auth_type = "oauth"
oauth_provider = "claude"

[profiles.models]
haiku = "claude-haiku-4-20250514"
sonnet = "claude-sonnet-4-20250514"
opus = "claude-opus-4-20250514"
```

<Aside type="note">
  Claude OAuth profile 使用特殊的 gateway 認證模式。Claudex 跳過代理，讓 Claude Code 直接使用自身的 OAuth。無需單獨的 `claudex auth login` 步驟。
</Aside>

### ChatGPT Plus / Codex CLI

透過 Codex CLI token 使用你的 ChatGPT Plus 或 Pro 訂閱。

**先決條件**：安裝 [Codex CLI](https://github.com/openai/codex) 並完成認證：

```bash
# 安裝 Codex CLI
npm install -g @openai/codex

# 認證（開啟瀏覽器）
codex auth
```

然後設定 Claudex：

```toml
[[profiles]]
name = "codex-sub"
provider_type = "OpenAIResponses"
base_url = "https://chatgpt.com/backend-api/codex"
default_model = "gpt-5.3-codex"
auth_type = "oauth"
oauth_provider = "openai"

[profiles.models]
haiku = "codex-mini-latest"
sonnet = "gpt-5.3-codex"
opus = "gpt-5.3-codex"
```

```bash
# 從 Codex CLI 讀取 token
claudex auth login openai --profile codex-sub

# 驗證
claudex auth status

# 執行
claudex run codex-sub
```

<Aside type="tip">
  Codex 端點支援的模型：`gpt-5.3-codex`、`gpt-5.1-codex`、`codex-mini-latest`。注意 `gpt-4o` 在 `chatgpt.com` Codex 端點上不受支援。`strip_params = "auto"` 會自動偵測此端點並移除 `temperature`/`top_p`/`top_k`。
</Aside>

### Google Gemini

透過 Gemini CLI 憑證使用你的 Google 帳戶。

```toml
[[profiles]]
name = "gemini-sub"
provider_type = "OpenAICompatible"
base_url = "https://generativelanguage.googleapis.com/v1beta/openai"
default_model = "gemini-2.5-pro"
auth_type = "oauth"
oauth_provider = "google"

[profiles.models]
haiku = "gemini-2.0-flash"
sonnet = "gemini-2.5-pro"
opus = "gemini-2.5-pro"
```

```bash
# 登入時從 Gemini CLI 憑證讀取
claudex auth login google --profile gemini-sub

# 驗證
claudex auth status
```

### Qwen / 通義千問

透過 OAuth Device Code 流程使用你的 Qwen 帳戶。

```toml
[[profiles]]
name = "qwen-oauth"
provider_type = "OpenAICompatible"
base_url = "https://chat.qwen.ai/api"
default_model = "qwen3-235b-a22b"
auth_type = "oauth"
oauth_provider = "qwen"
```

```bash
# 啟動 Device Code 流程
claudex auth login qwen --profile qwen-oauth

# 驗證
claudex auth status
```

### Kimi / Moonshot（OAuth）

透過 Kimi CLI 憑證使用你的 Kimi 帳戶。

```toml
[[profiles]]
name = "kimi-oauth"
provider_type = "OpenAICompatible"
base_url = "https://api.moonshot.cn/v1"
default_model = "moonshot-v1-128k"
auth_type = "oauth"
oauth_provider = "kimi"
```

```bash
# 登入時從 Kimi CLI 憑證讀取
claudex auth login kimi --profile kimi-oauth

# 驗證
claudex auth status
```

### GitHub Copilot

透過 OAuth Device Code 流程使用你的 GitHub Copilot 訂閱。

```toml
[[profiles]]
name = "copilot"
provider_type = "OpenAICompatible"
base_url = "https://api.githubcopilot.com"
default_model = "gpt-4o"
auth_type = "oauth"
oauth_provider = "github"
```

```bash
# 啟動 Device Code 流程（開啟瀏覽器進行 GitHub 登入）
claudex auth login github --profile copilot

# 驗證
claudex auth status
```

### GitLab Duo

透過 Personal Access Token 使用你的 GitLab Duo 訂閱。

```toml
[[profiles]]
name = "gitlab-duo"
provider_type = "OpenAICompatible"
base_url = "https://gitlab.com/api/v4/ai/llm/proxy"
default_model = "claude-sonnet-4-20250514"
auth_type = "oauth"
oauth_provider = "gitlab"
```

```bash
# 將 GitLab token 設為環境變數
export GITLAB_TOKEN=glpat-...

# 登入
claudex auth login gitlab --profile gitlab-duo

# 驗證
claudex auth status
```

<Aside type="note">
  GitLab Duo 需要 `GITLAB_TOKEN` 環境變數，使用具有 `ai_features` 範圍的 Personal Access Token。自行管理的 GitLab 實例請相應更新 `base_url`。
</Aside>

## 本地模型

### Ollama

1. 安裝 Ollama：[ollama.com](https://ollama.com/)
2. 拉取模型：

```bash
ollama pull qwen2.5:72b
```

3. 設定 Claudex：

```toml
[[profiles]]
name = "local-qwen"
provider_type = "OpenAICompatible"
base_url = "http://localhost:11434/v1"
api_key = ""
default_model = "qwen2.5:72b"
```

```bash
claudex profile test local-qwen
```

<Aside type="note">
  Ollama 不需要 API 金鑰。將 `api_key` 留空或省略即可。
</Aside>

### vLLM

1. 安裝並啟動 vLLM：

```bash
pip install vllm
vllm serve meta-llama/Llama-3.3-70B-Instruct --port 8000
```

2. 設定 Claudex：

```toml
[[profiles]]
name = "local-llama"
provider_type = "OpenAICompatible"
base_url = "http://localhost:8000/v1"
api_key = ""
default_model = "meta-llama/Llama-3.3-70B-Instruct"
```

### LM Studio

1. 從 [lmstudio.ai](https://lmstudio.ai/) 下載 LM Studio
2. 載入模型並啟動本地伺服器（預設連接埠：1234）

```toml
[[profiles]]
name = "lm-studio"
provider_type = "OpenAICompatible"
base_url = "http://localhost:1234/v1"
api_key = "lm-studio"
default_model = "local-model"
```

## 驗證你的設定

設定任何提供商後，驗證連線：

```bash
# 測試特定 profile
claudex profile test <profile-name>

# 測試所有 profile
claudex profile test all

# 列出所有已設定的 profile
claudex profile list
```
